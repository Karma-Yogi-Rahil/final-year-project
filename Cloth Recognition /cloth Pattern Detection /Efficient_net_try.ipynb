{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Efficient net try.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tflite-model-maker\n",
        "!pip install -q pycocotools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLJ2aEpYWiCI",
        "outputId": "370b72bb-1185-47d0-b51a-503eeb7f234c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 616 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 77 kB 4.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 39.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 36.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 47.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 31.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 40.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 44.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 36.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 213 kB 53.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 840 kB 23.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 25.3 MB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 47.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 66 kB/s \n",
            "\u001b[K     |████████████████████████████████| 211 kB 45.5 MB/s \n",
            "\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KIiGgSlrVqh7"
      },
      "outputs": [],
      "source": [
        "from tensorflow_examples.lite.model_maker.core.data_util.image_dataloader import ImageClassifierDataLoader\n",
        "from tensorflow_examples.lite.model_maker.core.task import image_classifier\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tflite_model_maker.image_classifier "
      ],
      "metadata": {
        "id": "hHjhw5XVY0Ac"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2hKvIPlxV8yA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/tensorflow/examples.git#egg=tensorflow-examples[model_maker]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1khidlRSV9VP",
        "outputId": "c8a80178-75be-46cf-e7f3-e5675a6df988"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: tensorflow-examples 86e95a594ffd7a74016a2b15991d2294725d7e28- does not provide the extra 'model_maker'\u001b[0m\n",
            "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  WARNING: Built wheel for tensorflow-examples is invalid: Metadata 1.2 mandates PEP 440 version, but '86e95a594ffd7a74016a2b15991d2294725d7e28-' is not\u001b[0m\n",
            "    Running setup.py install for tensorflow-examples ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: tensorflow-examples was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'"
      ],
      "metadata": {
        "id": "MVQhgi0AXZhI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d rahilmehtaucoe2784/cloth-pattern"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qcz9Tj2VXZjt",
        "outputId": "9dea2c11-9c95-4f3c-e55c-146569f43e7b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading cloth-pattern.zip to /content\n",
            " 99% 1.69G/1.70G [00:56<00:00, 32.6MB/s]\n",
            "100% 1.70G/1.70G [00:56<00:00, 32.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip \\*.zip && rm *.zip &> /dev/null"
      ],
      "metadata": {
        "id": "zTL1-MmOXZmG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/NEW LARGE IMAGE \"\n",
        "data = ImageClassifierDataLoader.from_folder(image_path)\n",
        "train_data, rest_data = data.split(0.8)\n",
        "validation_data = rest_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHKSZBt7V9Sp",
        "outputId": "ce198063-da87-450b-b6d5-1a3ce69c6ce9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Load image with size: 4710, num_label: 7, labels: checkered, dots, florals , horizontal strip, paisley pattern, vertical strip, zig zag .\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Load image with size: 4710, num_label: 7, labels: checkered, dots, florals , horizontal strip, paisley pattern, vertical strip, zig zag .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = image_classifier.create(train_data, \n",
        "                                model_spec= tflite_model_maker.image_classifier.EfficientNetLite0Spec(), \n",
        "                                epochs=5, \n",
        "                                #validation_data=validation_data\n",
        "                                )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w0zRMN4NYA-9",
        "outputId": "7a7d79ee-ec89-47fd-f417-72f1efd35641"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Retraining the models...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hub_keras_layer_v1v2_2 (Hub  (None, 1280)             3413024   \n",
            " KerasLayerV1V2)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 7)                 8967      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,421,991\n",
            "Trainable params: 8,967\n",
            "Non-trainable params: 3,413,024\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "115/117 [============================>.] - ETA: 3s - loss: 0.9642 - accuracy: 0.7807"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-54ae4bb24f24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model = image_classifier.create(train_data, \n\u001b[1;32m      2\u001b[0m                                 \u001b[0mmodel_spec\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtflite_model_maker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEfficientNetLite0Spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                                 \u001b[0;31m#validation_data=validation_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_examples/lite/model_maker/core/task/image_classifier.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, train_data, model_spec, validation_data, batch_size, epochs, steps_per_epoch, train_whole_model, dropout_rate, learning_rate, momentum, shuffle, use_augmentation, use_hub_library, warmup_steps, model_dir, do_train)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Retraining the models...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m       \u001b[0mimage_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;31m# Used in evaluation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_examples/lite/model_maker/core/task/image_classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, validation_data, hparams, steps_per_epoch)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mtrain_ds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mvalidation_ds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         steps_per_epoch=steps_per_epoch)\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   def _export_tflite(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_examples/lite/model_maker/core/task/train_image_classifier_lib.py\u001b[0m in \u001b[0;36mhub_train_model\u001b[0;34m(model, hparams, train_ds, validation_ds, steps_per_epoch)\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m       validation_data=validation_ds)\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) INVALID_ARGUMENT:  jpeg::Uncompress failed. Invalid JPEG data or crop window.\n\t [[{{node cond/DecodeJpeg}}]]\n\t [[IteratorGetNext]]\n\t [[IteratorGetNext/_4]]\n  (1) INVALID_ARGUMENT:  jpeg::Uncompress failed. Invalid JPEG data or crop window.\n\t [[{{node cond/DecodeJpeg}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_38289]\n\nFunction call stack:\ntrain_function -> train_function -> train_function -> train_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from struct import unpack\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "\n",
        "marker_mapping = {\n",
        "    0xffd8: \"Start of Image\",\n",
        "    0xffe0: \"Application Default Header\",\n",
        "    0xffdb: \"Quantization Table\",\n",
        "    0xffc0: \"Start of Frame\",\n",
        "    0xffc4: \"Define Huffman Table\",\n",
        "    0xffda: \"Start of Scan\",\n",
        "    0xffd9: \"End of Image\"\n",
        "}\n",
        "\n",
        "\n",
        "class JPEG:\n",
        "    def __init__(self, image_file):\n",
        "        with open(image_file, 'rb') as f:\n",
        "            self.img_data = f.read()\n",
        "    \n",
        "    def decode(self):\n",
        "        data = self.img_data\n",
        "        while(True):\n",
        "            marker, = unpack(\">H\", data[0:2])\n",
        "            # print(marker_mapping.get(marker))\n",
        "            if marker == 0xffd8:\n",
        "                data = data[2:]\n",
        "            elif marker == 0xffd9:\n",
        "                return\n",
        "            elif marker == 0xffda:\n",
        "                data = data[-2:]\n",
        "            else:\n",
        "                lenchunk, = unpack(\">H\", data[2:4])\n",
        "                data = data[2+lenchunk:]            \n",
        "            if len(data)==0:\n",
        "               raise TypeError(\"issue reading jpeg file\")           \n",
        "\n",
        "\n",
        "bads = []\n",
        "\n",
        "image_path = '/content/NEW LARGE IMAGE /zig zag '\n",
        "for dirName, subdirList, fileList in os.walk(image_path):\n",
        "    imagesList = fileList\n",
        "    for img in tqdm(imagesList):\n",
        "      image = os.path.join(image_path,img)\n",
        "      image = JPEG(image) \n",
        "    try:\n",
        "      image.decode()   \n",
        "    except:\n",
        "      bads.append(img)\n",
        "\n",
        "print(bads)\n",
        "for name in bads:\n",
        "  os.remove(osp.join(root_img,name))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_H8jgAuhXXy",
        "outputId": "48d35c5a-4527-436e-d9a7-e3875e1af538"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 560/560 [00:00<00:00, 3886.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0trQ3cx7kDPa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}